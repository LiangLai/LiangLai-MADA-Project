---
title: "Association between Body Mass Index Variability and Subsequent Dementia Risk in Older Adults"
author: "Liang Lai"
format:
  docx:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../../assets/dataanalysis-references.bib
csl: ../../assets/american-journal-of-epidemiology.csl
---



```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)
library(haven)
```


**Authors**  

* Liang Lai$^{1,*}$ (ORCID: 0000-0000-1234-5678) 


**Author affiliations**  

1. College of Public Health, University of Georgia, Athens, GA, USA.


{{< pagebreak >}}



# Summary/Abstract
_Write a summary of your project._

_It is recommended to use a structured abstract with Background/Methods/Results/Discussion sections._

{{< pagebreak >}}


# Introduction 

## General Background Information
Mid-life high body mass index (BMI) has been linked to poorer cognitive performance, faster cognitive decline, and higher risk of dementia in later life, but little is known about whether a more unstable BMI over time is associated with worse cognitive outcomes. This study investigated the relationship between long-term BMI variability (BMIV) and dementia risk in older adults in the US.

## Description of data and data source
We will use data from the Health and Retirement Study (HRS), a nationally representative longitudinal survey of U.S. adults aged 50+, with biennial follow-up. The study period spans 1996–2020 (up to 13 waves). HRS collects repeated measures on demographics, socioeconomic status, health behaviors, and health conditions, and includes cognitive assessments that allow dementia classification. We will use publicly available HRS/RAND HRS data files that can be shared within the class repository to ensure full reproducibility.
The analytic dataset will be constructed at the person-wave level and then converted into an incident-event (time-to-event) format for survival analysis. Key measures include repeated BMI observations over time, baseline covariates (e.g., age, sex, race/ethnicity, education), and time-varying health and lifestyle factors where available. Because HRS is a real-world longitudinal survey, it contains typical “messy” features (e.g., missingness across waves, irregular observation patterns, attrition, and measurement variability), which requires explicit data cleaning and processing.

## Quick check data 

```{r}
# path to data
# note the use of the here() package and not absolute paths 
# and  the raw data is stata edition
hrs_raw <- read_dta(here("data","raw-data","randhrs1992_2022v1.dta"))
```
```{r}
glimpse(hrs_raw)
head(hrs_raw)
```

The raw RAND HRS dataset used in this project contains 45,234 observations (rows) and 19,880 variables (columns). The large number of variables is primarily due to the longitudinal structure of HRS: many measures are repeated across multiple survey waves, and the same concept is stored as wave-specific variables. In RAND HRS, these repeated measures are often organized using wave identifiers (e.g., r1, r2, r3, …), corresponding to survey waves over time (up to ~16 waves depending on the measure and harmonization). As a result, a single construct (e.g., BMI, cognition, health conditions) may appear in multiple wave-specific versions, substantially increasing the total column count.

We will extract the wave-specific BMI and cognition variables needed for the analysis, and then restructure the data into a person-period (long) format to support BMI variability window construction and time-to-event modeling.

## Questions/Hypotheses to be addressed
* Primary research question: Is greater long-term BMI variability associated with a higher risk of incident dementia among U.S. adults aged 50+?


{{< pagebreak >}}

# Planned Methods
We will construct BMI variability (BMIV) as the coefficient of variation (CV) of repeated BMI measurements across fixed windows. And we will use Cox hazards regression model.



-------------------------Planing-----------------------------


## Schematic of workflow(Planing)

Sometimes you might want to show a schematic diagram/figure that was not created with code (if you can do it with code, do it). @fig-schematic is an example of some - completely random/unrelated - schematic that was generated with BioRender.
We store those figures in the `assets` folder.

```{r}
#| label: fig-schematic
#| fig-cap: "A figure that is manually generated and shows some overview/schematic. This has nothing to do with the data, it's just a random one from one of our projects I found and placed here."
#| echo: FALSE
knitr::include_graphics(here("assets","antigen-recognition.png"))
```

## Data acquisition 
_As applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next._


## Data import and cleaning
_Write code that reads in the file and cleans it so it's ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along._


## Statistical analysis
_Explain anything related to your statistical analyses._


{{< pagebreak >}}


# Results

## Exploratory/Descriptive analysis

_Use a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project._


@tbl-summarytable shows a summary of the data.

Note the loading of the data providing a **relative** path using the `../../` notation. (Two dots means a folder up). You never want to specify an **absolute** path like `C:\ahandel\myproject\results\` because if you share this with someone, it won't work for them since they don't have that path. You can also use the `here` R package to create paths. See examples of that below. I generally recommend the `here` package.

```{r}
#| label: tbl-summarytable
#| tbl-cap: "Data summary table."
#| echo: FALSE
resulttable <- readRDS("../../results/tables/summarytable.rds")
knitr::kable(resulttable)
```



## Basic statistical analysis

_To get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p<0.05 means statistical significance" interpretation is not valid._


@fig-result shows a scatterplot figure produced by one of the R scripts.

```{r}
#| label: fig-result
#| fig-cap: "Height and weight stratified by gender."
#| echo: FALSE
knitr::include_graphics(here("results","figures","height-weight-stratified.png"))
```


## Full analysis

_Use one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here._

Example @tbl-resulttable2 shows a summary of a linear model fit.

```{r}
#| label: tbl-resulttable2
#| tbl-cap: "Linear model fit table."
#| echo: FALSE
resulttable2 <- readRDS(here("results","tables","resulttable2.rds"))
knitr::kable(resulttable2)
```


{{< pagebreak >}}


# Discussion

## Summary and Interpretation
_Summarize what you did, what you found and what it means._

## Strengths and Limitations
_Discuss what you perceive as strengths and limitations of your analysis._

## Conclusions
_What are the main take-home messages?_

_Include citations in your Qmd file using BibTeX, the list of references will automatically be placed at the end_

This paper [@leek2015] discusses types of analyses. 

These papers [@mckay2020; @mckay2020a] are good examples of papers published using a fully reproducible setup similar to the one shown in this template. 

Note that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal [are available](https://www.zotero.org/styles). You also specify the location of your BibTeX reference file in the YAML. You can call your reference file anything you like.


{{< pagebreak >}}

# References



