---
title: "Cleaning and processing code for HRS data"
author: "Liang Lai"
date: "2026-02-27"
output: html_document
---

# Setup

Load needed packages. make sure they are installed.
```{r}
library(readxl) #for loading Excel files
library(dplyr) #for data processing/cleaning
library(tidyr) #for data processing/cleaning
library(skimr) #for nice visualization of data 
library(here) #to set paths
library(haven) # for load stata data
```

# Data loading
```{r}
# path to data
# note the use of the here() package and not absolute paths
hrs_raw <- read_dta(here("data","raw-data","randhrs1992_2022v1.dta"))
```

```{r}
# 2. select 100 sample
set.seed(123) 
hrs_sample_100 <- hrs_raw %>%
  slice_sample(n = 100)

# 3. save to processed-data 
saveRDS(hrs_sample_100, here("data", "processed-data", "randhrs_sample_100.rds"))
```


# Check data 
First we can look at the data. At this point, the data is wide and we will need to reshape it to long format for analysis, but we can still check the data in its current form. We can find there are different waves of data collection, and each wave has a set of variables (including 16waves from 1992-2022 ). For example, the first wave (1992) has variables like r1bmi, r1age, r1sex, etc., and the second wave (1994) has variables like r2bmi, r2age, r2sex, etc. We can also see that there are some missing values in the data.

```{r}
glimpse(hrs_sample_100)
head(hrs_sample_100)
```


# Cleaning

Next, follow the following steps to process the data:

1. reshape the data from wide to long format, so that each row represents a person-wave observation.
```{r}
d1 <- rawdata %>% dplyr::filter( Height != "sixty" ) %>% 
                  dplyr::mutate(Height = as.numeric(Height))
skimr::skim(d1)
hist(d1$Height)
```


2. select the relevant variables for analysis



Now we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. We assume that we know it was a mistaken entry as feet and convert to centimeters. Depending on your knowledge of the data, you might instead want to remove this person.

```{r}
d2 <- d1 %>% dplyr::mutate( Height = replace(Height, Height=="6",round(6*30.48,0)) )
skimr::skim(d2)
```

Height values seem ok now.

Now let's look at the `Weight` variable. There is a person with weight of 7000, which is impossible, and one person with missing weight.
To be able to analyze the data, we'll remove those individuals as well.

```{r}
d3 <- d2 %>%  dplyr::filter(Weight != 7000) %>% tidyr::drop_na()
skimr::skim(d3)
```

Now checking the `Gender` variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.

```{r}
d3$Gender <- as.factor(d3$Gender)  
skimr::skim(d3)
```


Now we see that there is another NA, but it's not `NA` from R, instead it was loaded as character and is now considered as a category.
We'll proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I'm also using droplevels() to get rid of it.

```{r}
d4 <- d3 %>% dplyr::filter( !(Gender %in% c("NA","N")) ) %>% droplevels()
skimr::skim(d4)
```


All done, data is clean now. 

Let's assign at the end to some final variable, this makes it easier to add further cleaning steps above.

```{r}
processeddata <- d4
```


# Save data 

Finally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. 
This preserves coding like factors, characters, numeric, etc.  If you save as CSV, that information would get lost.
However, CSV is better for sharing with others since it's plain text. If you do CSV, you might want to write down somewhere what each variable is.

See here for some suggestions on how to store your processed data:
http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata

```{r}
save_data_location <- here::here("data","processed-data","processeddata.rds")
saveRDS(processeddata, file = save_data_location)
```



# Notes

Removing anyone who had "faulty" or missing data is one approach. It's often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep individuals with some missing information).

